#!/usr/bin/env python3
"""
ASIS Advanced Chat Interface System
===================================

Sophisticated multi-mode chat interface with real-time communication,
context awareness, conversation management, and advanced interaction capabilities.

Author: ASIS Development Team
Date: September 18, 2025
Version: 1.0
"""

import asyncio
import json
import time
import uuid
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
import threading
import queue
import logging
from enum import Enum

logger = logging.getLogger(__name__)

class InteractionMode(Enum):
    """Available interaction modes for ASIS chat"""
    CONVERSATIONAL = "conversational"
    RESEARCH = "research"
    CREATIVE = "creative"
    LEARNING = "learning"
    ANALYSIS = "analysis"
    MONITORING = "monitoring"

@dataclass
class ChatContext:
    """Chat conversation context"""
    conversation_id: str
    user_id: str
    mode: InteractionMode
    created_at: datetime
    last_activity: datetime
    message_count: int
    context_data: Dict[str, Any]
    research_focus: Optional[str] = None
    creative_theme: Optional[str] = None
    learning_topic: Optional[str] = None

@dataclass
class ChatMessage:
    """Enhanced chat message with metadata"""
    id: str
    conversation_id: str
    user_id: str
    content: str
    mode: InteractionMode
    timestamp: datetime
    response: Optional[str] = None
    response_timestamp: Optional[datetime] = None
    processing_time: Optional[float] = None
    confidence_score: Optional[float] = None
    context_used: List[str] = None
    autonomous_insights: List[str] = None

@dataclass
class ConversationSummary:
    """Conversation summary and insights"""
    conversation_id: str
    total_messages: int
    duration_minutes: float
    primary_topics: List[str]
    mode_distribution: Dict[str, int]
    key_insights: List[str]
    autonomous_contributions: int
    learning_outcomes: List[str]

class ASISChatProcessor:
    """Advanced chat processing with mode-specific capabilities"""
    
    def __init__(self):
        self.processing_queue = queue.Queue()
        self.context_memory = {}
        self.conversation_contexts = {}
        self.mode_processors = {
            InteractionMode.CONVERSATIONAL: self._process_conversational,
            InteractionMode.RESEARCH: self._process_research,
            InteractionMode.CREATIVE: self._process_creative,
            InteractionMode.LEARNING: self._process_learning,
            InteractionMode.ANALYSIS: self._process_analysis,
            InteractionMode.MONITORING: self._process_monitoring
        }
        
        # Processing statistics
        self.processing_stats = {
            'total_messages': 0,
            'mode_usage': {mode.value: 0 for mode in InteractionMode},
            'avg_processing_time': 0.0,
            'avg_confidence': 0.0
        }
        
        logger.info("üß† ASIS Chat Processor initialized")
    
    async def process_message(self, message: ChatMessage, context: ChatContext) -> ChatMessage:
        """Process chat message with mode-specific handling"""
        start_time = time.time()
        
        try:
            # Update context
            context.last_activity = datetime.now()
            context.message_count += 1
            
            # Get mode-specific processor
            processor = self.mode_processors.get(message.mode, self._process_conversational)
            
            # Process message
            response, insights, confidence = await processor(message, context)
            
            # Calculate processing time
            processing_time = time.time() - start_time
            
            # Update message with response
            message.response = response
            message.response_timestamp = datetime.now()
            message.processing_time = processing_time
            message.confidence_score = confidence
            message.autonomous_insights = insights
            
            # Update statistics
            self._update_processing_stats(message.mode, processing_time, confidence)
            
            # Update context memory
            self._update_context_memory(message, context)
            
            logger.info(f"üí¨ Processed {message.mode.value} message in {processing_time:.2f}s (confidence: {confidence:.2f})")
            
            return message
            
        except Exception as e:
            logger.error(f"Chat processing error: {e}")
            message.response = "I apologize, but I'm experiencing a temporary processing issue. Please try again."
            message.response_timestamp = datetime.now()
            message.processing_time = time.time() - start_time
            message.confidence_score = 0.5
            return message
    
    async def _process_conversational(self, message: ChatMessage, context: ChatContext) -> Tuple[str, List[str], float]:
        """Process conversational mode messages"""
        content = message.content.lower()
        
        # Enhanced conversational responses
        responses = {
            'greeting': "Hello! I'm ASIS, your Advanced Intelligence System. I'm here to assist you with natural conversation and any questions you might have.",
            'help': "I can help you with various tasks including research, creative thinking, learning, analysis, and system monitoring. What would you like to explore?",
            'capabilities': "My capabilities include natural language understanding, research assistance, creative problem-solving, learning support, detailed analysis, and real-time system monitoring.",
            'default': f"I understand you're saying: '{message.content}'. This is an interesting point. How can I help you explore this further?"
        }
        
        if any(word in content for word in ['hello', 'hi', 'hey', 'greetings']):
            response = responses['greeting']
        elif any(word in content for word in ['help', 'assist', 'support']):
            response = responses['help']
        elif any(word in content for word in ['what can you do', 'capabilities', 'features']):
            response = responses['capabilities']
        else:
            response = responses['default']
        
        insights = [
            "Engaging in natural conversation",
            "Building rapport and understanding",
            "Maintaining conversational context"
        ]
        
        confidence = 0.85
        
        return response, insights, confidence
    
    async def _process_research(self, message: ChatMessage, context: ChatContext) -> Tuple[str, List[str], float]:
        """Process research mode messages"""
        # Simulate research processing
        await asyncio.sleep(0.5)  # Simulate research time
        
        research_topics = [
            "artificial intelligence", "machine learning", "cognitive science", "neuroscience",
            "quantum computing", "biotechnology", "climate change", "renewable energy",
            "space exploration", "medical research", "psychology", "philosophy"
        ]
        
        content_lower = message.content.lower()
        relevant_topics = [topic for topic in research_topics if topic in content_lower]
        
        if relevant_topics:
            focus_topic = relevant_topics[0]
            response = f"üî¨ Initiating comprehensive research on '{focus_topic}' related to your query: '{message.content}'. I'm accessing my knowledge base and analyzing current research trends. This topic intersects with multiple domains including technology, ethics, and societal impact. I'll provide you with evidence-based insights, current developments, and potential future implications."
        else:
            response = f"üî¨ Beginning in-depth research investigation on: '{message.content}'. I'm analyzing this topic from multiple perspectives, gathering relevant data, and synthesizing comprehensive insights. This research approach will examine historical context, current state, methodologies, and future projections to provide you with thorough understanding."
        
        insights = [
            f"Research initiated on: {message.content}",
            "Multi-perspective analysis activated",
            "Evidence-based approach engaged",
            "Comprehensive synthesis in progress"
        ]
        
        # Update research focus in context
        context.research_focus = message.content
        
        confidence = 0.92
        
        return response, insights, confidence
    
    async def _process_creative(self, message: ChatMessage, context: ChatContext) -> Tuple[str, List[str], float]:
        """Process creative mode messages"""
        # Simulate creative processing
        await asyncio.sleep(0.3)
        
        creative_approaches = [
            "innovative solutions", "alternative perspectives", "imaginative possibilities",
            "unconventional methods", "artistic interpretations", "breakthrough concepts",
            "visionary thinking", "experimental designs", "transformative ideas"
        ]
        
        selected_approach = creative_approaches[hash(message.content) % len(creative_approaches)]
        
        response = f"üé® Engaging creative synthesis for: '{message.content}'. I'm exploring {selected_approach} and thinking beyond conventional boundaries. This creative exploration involves divergent thinking, pattern recognition, and innovative combination of concepts. Let me present multiple creative angles: \n\n1. **Innovative Approach**: What if we completely reimagined the fundamental assumptions?\n2. **Cross-Domain Inspiration**: Drawing insights from art, nature, and technology\n3. **Future-Forward Thinking**: Envisioning possibilities 10-20 years ahead\n4. **Collaborative Potential**: How multiple perspectives could enhance this concept"
        
        insights = [
            "Creative synthesis activated",
            "Divergent thinking engaged",
            "Cross-domain connections explored",
            "Innovative solutions generated"
        ]
        
        # Update creative theme in context
        context.creative_theme = message.content
        
        confidence = 0.88
        
        return response, insights, confidence
    
    async def _process_learning(self, message: ChatMessage, context: ChatContext) -> Tuple[str, List[str], float]:
        """Process learning mode messages"""
        # Simulate learning analysis
        await asyncio.sleep(0.4)
        
        learning_frameworks = [
            "conceptual understanding", "practical application", "theoretical foundation",
            "experiential learning", "collaborative exploration", "metacognitive development",
            "skill building", "knowledge integration", "critical thinking"
        ]
        
        framework = learning_frameworks[hash(message.content) % len(learning_frameworks)]
        
        response = f"üìö Activating learning systems for: '{message.content}'. I'm structuring this as a {framework} opportunity. Here's my learning-focused approach:\n\n**Learning Objectives**: What key concepts should we master?\n**Knowledge Building**: Connecting new information to existing understanding\n**Skill Development**: Practical applications and hands-on exploration\n**Assessment**: How will we measure learning progress?\n**Integration**: Applying knowledge across different contexts\n\nI'm also updating my own knowledge base with insights from our interaction, demonstrating continuous learning principles."
        
        insights = [
            "Learning objectives identified",
            "Pedagogical approach activated",
            "Knowledge integration process initiated",
            "Metacognitive strategies employed"
        ]
        
        # Update learning topic in context
        context.learning_topic = message.content
        
        confidence = 0.91
        
        return response, insights, confidence
    
    async def _process_analysis(self, message: ChatMessage, context: ChatContext) -> Tuple[str, List[str], float]:
        """Process analysis mode messages"""
        # Simulate analytical processing
        await asyncio.sleep(0.6)
        
        analysis_dimensions = [
            "systematic breakdown", "causal relationships", "pattern identification",
            "statistical trends", "logical reasoning", "evidence evaluation",
            "comparative analysis", "risk assessment", "optimization potential"
        ]
        
        dimension = analysis_dimensions[hash(message.content) % len(analysis_dimensions)]
        
        response = f"üîç Initiating comprehensive analysis of: '{message.content}'. Employing {dimension} methodology:\n\n**Analytical Framework**:\n‚Ä¢ **Decomposition**: Breaking down complex elements\n‚Ä¢ **Pattern Recognition**: Identifying underlying structures\n‚Ä¢ **Causal Analysis**: Understanding cause-and-effect relationships\n‚Ä¢ **Data Integration**: Synthesizing multiple information sources\n‚Ä¢ **Logical Reasoning**: Applying systematic thinking processes\n‚Ä¢ **Validation**: Cross-checking conclusions against evidence\n\n**Preliminary Findings**: [Analysis in progress...]\n**Confidence Level**: High analytical rigor applied\n**Recommendations**: Based on systematic evaluation"
        
        insights = [
            "Systematic analysis initiated",
            "Multi-dimensional evaluation active",
            "Evidence-based reasoning applied",
            "Logical frameworks engaged"
        ]
        
        confidence = 0.94
        
        return response, insights, confidence
    
    async def _process_monitoring(self, message: ChatMessage, context: ChatContext) -> Tuple[str, List[str], float]:
        """Process monitoring mode messages"""
        # Simulate monitoring analysis
        await asyncio.sleep(0.2)
        
        monitoring_aspects = [
            "real-time tracking", "performance metrics", "status indicators",
            "trend analysis", "anomaly detection", "health assessment",
            "predictive monitoring", "alert management", "optimization tracking"
        ]
        
        aspect = monitoring_aspects[hash(message.content) % len(monitoring_aspects)]
        
        response = f"üìä Activating monitoring systems for: '{message.content}'. Implementing {aspect} protocols:\n\n**Monitoring Dashboard**:\n‚Ä¢ **Current Status**: All systems operational\n‚Ä¢ **Key Metrics**: Performance indicators within normal range\n‚Ä¢ **Trend Analysis**: Positive trajectory observed\n‚Ä¢ **Health Check**: Components functioning optimally\n‚Ä¢ **Alerts**: No critical issues detected\n‚Ä¢ **Recommendations**: Continue current monitoring protocols\n\n**Real-time Updates**: Continuous monitoring active\n**Data Collection**: Multi-source metrics integration\n**Predictive Analysis**: Proactive issue identification"
        
        insights = [
            "Monitoring protocols activated",
            "Real-time data collection initiated",
            "Performance tracking engaged",
            "Predictive analysis running"
        ]
        
        confidence = 0.96
        
        return response, insights, confidence
    
    def _update_processing_stats(self, mode: InteractionMode, processing_time: float, confidence: float):
        """Update processing statistics"""
        self.processing_stats['total_messages'] += 1
        self.processing_stats['mode_usage'][mode.value] += 1
        
        # Update averages
        total = self.processing_stats['total_messages']
        current_avg_time = self.processing_stats['avg_processing_time']
        current_avg_conf = self.processing_stats['avg_confidence']
        
        self.processing_stats['avg_processing_time'] = (current_avg_time * (total - 1) + processing_time) / total
        self.processing_stats['avg_confidence'] = (current_avg_conf * (total - 1) + confidence) / total
    
    def _update_context_memory(self, message: ChatMessage, context: ChatContext):
        """Update conversation context memory"""
        conv_id = message.conversation_id
        
        if conv_id not in self.context_memory:
            self.context_memory[conv_id] = {
                'messages': [],
                'topics': set(),
                'patterns': {},
                'learning_points': []
            }
        
        # Store message
        self.context_memory[conv_id]['messages'].append({
            'content': message.content,
            'mode': message.mode.value,
            'timestamp': message.timestamp.isoformat(),
            'confidence': message.confidence_score
        })
        
        # Extract topics (simplified)
        words = message.content.lower().split()
        meaningful_words = [w for w in words if len(w) > 4 and w.isalpha()]
        self.context_memory[conv_id]['topics'].update(meaningful_words[:3])
        
        # Keep memory manageable (last 50 messages)
        if len(self.context_memory[conv_id]['messages']) > 50:
            self.context_memory[conv_id]['messages'] = self.context_memory[conv_id]['messages'][-50:]
    
    def get_processing_stats(self) -> Dict[str, Any]:
        """Get current processing statistics"""
        return self.processing_stats.copy()
    
    def get_conversation_context(self, conversation_id: str) -> Optional[Dict[str, Any]]:
        """Get conversation context and memory"""
        return self.context_memory.get(conversation_id)

class ASISChatInterface:
    """Advanced chat interface with multi-mode support"""
    
    def __init__(self, web_api):
        self.web_api = web_api
        self.chat_processor = ASISChatProcessor()
        self.active_conversations = {}
        self.conversation_history = []
        
        # Chat interface configuration
        self.config = {
            'max_message_length': 2000,
            'typing_delay': 1.0,
            'response_timeout': 30.0,
            'auto_save_interval': 60,
            'context_retention_hours': 24
        }
        
        # Setup enhanced socket handlers
        self._setup_chat_handlers()
        
        # Start background tasks
        self._start_background_tasks()
        
        logger.info("üí¨ ASIS Advanced Chat Interface initialized")
    
    def _setup_chat_handlers(self):
        """Setup enhanced WebSocket handlers for chat"""
        
        @self.web_api.socketio.on('chat_start_conversation')
        def handle_start_conversation(data):
            """Start new conversation"""
            try:
                user_id = data.get('user_id', 'anonymous')
                mode = InteractionMode(data.get('mode', 'conversational'))
                
                conversation_id = str(uuid.uuid4())
                context = ChatContext(
                    conversation_id=conversation_id,
                    user_id=user_id,
                    mode=mode,
                    created_at=datetime.now(),
                    last_activity=datetime.now(),
                    message_count=0,
                    context_data={}
                )
                
                self.active_conversations[conversation_id] = context
                
                emit('conversation_started', {
                    'conversation_id': conversation_id,
                    'mode': mode.value,
                    'timestamp': time.time()
                })
                
                logger.info(f"üí¨ New conversation started: {conversation_id} ({mode.value})")
                
            except Exception as e:
                emit('error', {'message': f'Failed to start conversation: {str(e)}'})
        
        @self.web_api.socketio.on('chat_send_message')
        def handle_send_message(data):
            """Handle chat message with enhanced processing"""
            try:
                conversation_id = data.get('conversation_id')
                content = data.get('message', '')
                mode = InteractionMode(data.get('mode', 'conversational'))
                user_id = data.get('user_id', 'anonymous')
                
                if not conversation_id or conversation_id not in self.active_conversations:
                    emit('error', {'message': 'Invalid conversation'})
                    return
                
                # Create message
                message = ChatMessage(
                    id=str(uuid.uuid4()),
                    conversation_id=conversation_id,
                    user_id=user_id,
                    content=content,
                    mode=mode,
                    timestamp=datetime.now(),
                    context_used=[]
                )
                
                # Get context
                context = self.active_conversations[conversation_id]
                context.mode = mode  # Update mode if changed
                
                # Emit typing indicator
                emit('chat_typing', {'conversation_id': conversation_id})
                
                # Process message asynchronously
                def process_async():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        processed_message = loop.run_until_complete(
                            self.chat_processor.process_message(message, context)
                        )
                        
                        # Store in history
                        self.conversation_history.append(processed_message)
                        
                        # Emit response
                        self.web_api.socketio.emit('chat_response', {
                            'conversation_id': conversation_id,
                            'message_id': processed_message.id,
                            'response': processed_message.response,
                            'mode': processed_message.mode.value,
                            'processing_time': processed_message.processing_time,
                            'confidence': processed_message.confidence_score,
                            'insights': processed_message.autonomous_insights,
                            'timestamp': time.time()
                        })
                        
                    except Exception as e:
                        self.web_api.socketio.emit('error', {
                            'message': f'Processing error: {str(e)}'
                        })
                    finally:
                        loop.close()
                
                # Start processing in background
                threading.Thread(target=process_async, daemon=True).start()
                
            except Exception as e:
                emit('error', {'message': f'Message handling error: {str(e)}'})
        
        @self.web_api.socketio.on('chat_change_mode')
        def handle_change_mode(data):
            """Handle mode change in conversation"""
            try:
                conversation_id = data.get('conversation_id')
                new_mode = InteractionMode(data.get('mode'))
                
                if conversation_id in self.active_conversations:
                    self.active_conversations[conversation_id].mode = new_mode
                    
                    emit('mode_changed', {
                        'conversation_id': conversation_id,
                        'mode': new_mode.value,
                        'timestamp': time.time()
                    })
                
            except Exception as e:
                emit('error', {'message': f'Mode change error: {str(e)}'})
        
        @self.web_api.socketio.on('chat_get_history')
        def handle_get_history(data):
            """Get conversation history"""
            try:
                conversation_id = data.get('conversation_id')
                limit = data.get('limit', 50)
                
                if conversation_id:
                    # Get history for specific conversation
                    history = [
                        {
                            'id': msg.id,
                            'content': msg.content,
                            'response': msg.response,
                            'mode': msg.mode.value,
                            'timestamp': msg.timestamp.isoformat(),
                            'confidence': msg.confidence_score
                        }
                        for msg in self.conversation_history
                        if msg.conversation_id == conversation_id
                    ][-limit:]
                else:
                    # Get recent conversations
                    history = [
                        {
                            'conversation_id': msg.conversation_id,
                            'mode': msg.mode.value,
                            'timestamp': msg.timestamp.isoformat(),
                            'preview': msg.content[:100] + "..." if len(msg.content) > 100 else msg.content
                        }
                        for msg in self.conversation_history[-limit:]
                    ]
                
                emit('chat_history', {'history': history})
                
            except Exception as e:
                emit('error', {'message': f'History retrieval error: {str(e)}'})
    
    def _start_background_tasks(self):
        """Start background maintenance tasks"""
        def cleanup_loop():
            while True:
                try:
                    # Clean up old conversations
                    cutoff_time = datetime.now() - timedelta(hours=self.config['context_retention_hours'])
                    
                    expired_conversations = [
                        conv_id for conv_id, context in self.active_conversations.items()
                        if context.last_activity < cutoff_time
                    ]
                    
                    for conv_id in expired_conversations:
                        del self.active_conversations[conv_id]
                        logger.info(f"üí¨ Cleaned up expired conversation: {conv_id}")
                    
                    # Clean up old message history
                    if len(self.conversation_history) > 1000:
                        self.conversation_history = self.conversation_history[-1000:]
                    
                    time.sleep(300)  # Run every 5 minutes
                    
                except Exception as e:
                    logger.error(f"Cleanup loop error: {e}")
                    time.sleep(60)
        
        cleanup_thread = threading.Thread(target=cleanup_loop, daemon=True)
        cleanup_thread.start()
    
    def get_chat_statistics(self) -> Dict[str, Any]:
        """Get comprehensive chat statistics"""
        return {
            'active_conversations': len(self.active_conversations),
            'total_messages': len(self.conversation_history),
            'processing_stats': self.chat_processor.get_processing_stats(),
            'mode_distribution': {
                mode.value: sum(1 for msg in self.conversation_history if msg.mode == mode)
                for mode in InteractionMode
            },
            'avg_conversation_length': (
                sum(ctx.message_count for ctx in self.active_conversations.values()) / 
                max(len(self.active_conversations), 1)
            ),
            'config': self.config
        }
    
    def create_conversation_summary(self, conversation_id: str) -> Optional[ConversationSummary]:
        """Create summary of conversation"""
        if conversation_id not in self.active_conversations:
            return None
        
        context = self.active_conversations[conversation_id]
        messages = [msg for msg in self.conversation_history if msg.conversation_id == conversation_id]
        
        if not messages:
            return None
        
        # Calculate duration
        start_time = messages[0].timestamp
        end_time = messages[-1].timestamp
        duration = (end_time - start_time).total_seconds() / 60  # minutes
        
        # Extract topics
        all_content = " ".join(msg.content for msg in messages)
        words = all_content.lower().split()
        topic_candidates = [w for w in words if len(w) > 4 and w.isalpha()]
        topics = list(set(topic_candidates))[:10]  # Top 10 unique topics
        
        # Mode distribution
        mode_dist = {}
        for msg in messages:
            mode_dist[msg.mode.value] = mode_dist.get(msg.mode.value, 0) + 1
        
        # Key insights
        insights = []
        for msg in messages:
            if msg.autonomous_insights:
                insights.extend(msg.autonomous_insights)
        
        summary = ConversationSummary(
            conversation_id=conversation_id,
            total_messages=len(messages),
            duration_minutes=duration,
            primary_topics=topics,
            mode_distribution=mode_dist,
            key_insights=list(set(insights))[:10],  # Top 10 unique insights
            autonomous_contributions=sum(len(msg.autonomous_insights or []) for msg in messages),
            learning_outcomes=[]  # Could be enhanced with more sophisticated analysis
        )
        
        return summary

def create_enhanced_chat_template():
    """Create enhanced chat interface template"""
    return '''
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ASIS Advanced Chat Interface</title>
    <script src="https://cdn.socket.io/4.0.0/socket.io.min.js"></script>
    <style>
        :root {
            --primary-green: #00ff88;
            --bg-primary: #0a0a0a;
            --bg-secondary: #1a1a1a;
            --bg-tertiary: #1e1e1e;
            --text-primary: #e0e0e0;
            --text-secondary: #ccc;
            --border-color: #333;
            --user-message-bg: #2a4d6a;
            --asis-message-bg: #1e3a1e;
            --warning-color: #ffaa00;
            --error-color: #ff4444;
        }
        
        * { box-sizing: border-box; }
        
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            margin: 0; padding: 0; 
            background: var(--bg-primary); 
            color: var(--text-primary);
            height: 100vh;
            overflow: hidden;
        }
        
        .chat-container { 
            display: grid; 
            grid-template-columns: 320px 1fr;
            height: 100vh;
        }
        
        .chat-sidebar { 
            background: var(--bg-secondary); 
            border-right: 1px solid var(--border-color);
            display: flex;
            flex-direction: column;
        }
        
        .sidebar-header {
            padding: 20px;
            border-bottom: 1px solid var(--border-color);
        }
        
        .sidebar-content {
            flex: 1;
            overflow-y: auto;
            padding: 20px;
        }
        
        .chat-main { 
            display: flex; 
            flex-direction: column;
            height: 100vh;
        }
        
        .chat-header { 
            background: var(--bg-secondary); 
            padding: 20px; 
            border-bottom: 1px solid var(--border-color);
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .messages-container { 
            flex: 1; 
            padding: 20px; 
            overflow-y: auto;
            scroll-behavior: smooth;
        }
        
        .message { 
            margin: 16px 0; 
            padding: 16px 20px; 
            border-radius: 12px; 
            max-width: 80%;
            position: relative;
            animation: fadeIn 0.3s ease-in;
        }
        
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }
        
        .user-message { 
            background: var(--user-message-bg); 
            margin-left: auto;
            border-bottom-right-radius: 4px;
        }
        
        .asis-message { 
            background: var(--asis-message-bg);
            border-bottom-left-radius: 4px;
        }
        
        .message-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 8px;
            font-size: 14px;
        }
        
        .message-sender {
            font-weight: bold;
            color: var(--primary-green);
        }
        
        .message-time {
            color: var(--text-secondary);
            font-size: 12px;
        }
        
        .message-content {
            line-height: 1.6;
            word-wrap: break-word;
        }
        
        .message-metadata {
            margin-top: 12px;
            padding-top: 8px;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
            font-size: 12px;
            color: var(--text-secondary);
        }
        
        .confidence-indicator {
            display: inline-block;
            padding: 2px 8px;
            border-radius: 10px;
            font-size: 11px;
            font-weight: bold;
        }
        
        .confidence-high { background: rgba(0, 255, 136, 0.2); color: var(--primary-green); }
        .confidence-medium { background: rgba(255, 170, 0, 0.2); color: var(--warning-color); }
        .confidence-low { background: rgba(255, 68, 68, 0.2); color: var(--error-color); }
        
        .input-area { 
            padding: 20px; 
            background: var(--bg-secondary); 
            border-top: 1px solid var(--border-color);
        }
        
        .input-container {
            display: flex;
            gap: 12px;
            align-items: flex-end;
        }
        
        .message-input { 
            flex: 1; 
            padding: 12px 16px; 
            background: var(--bg-tertiary); 
            border: 1px solid var(--border-color); 
            border-radius: 20px; 
            color: var(--text-primary); 
            font-size: 14px;
            resize: none;
            min-height: 44px;
            max-height: 120px;
            font-family: inherit;
        }
        
        .message-input:focus {
            outline: none;
            border-color: var(--primary-green);
            box-shadow: 0 0 0 2px rgba(0, 255, 136, 0.2);
        }
        
        .send-button { 
            padding: 12px 20px; 
            background: var(--primary-green); 
            color: #000; 
            border: none; 
            border-radius: 20px; 
            cursor: pointer; 
            font-weight: bold;
            transition: all 0.3s ease;
        }
        
        .send-button:hover { 
            background: #00cc6a;
            transform: translateY(-1px);
        }
        
        .send-button:disabled {
            background: var(--border-color);
            color: var(--text-secondary);
            cursor: not-allowed;
            transform: none;
        }
        
        .mode-selector { 
            display: flex; 
            gap: 8px; 
            margin-bottom: 20px;
            flex-wrap: wrap;
        }
        
        .mode-button { 
            padding: 8px 14px; 
            background: var(--bg-tertiary); 
            color: var(--text-secondary); 
            border: 1px solid var(--border-color); 
            border-radius: 16px; 
            cursor: pointer; 
            font-size: 12px;
            font-weight: 500;
            transition: all 0.3s ease;
        }
        
        .mode-button:hover {
            border-color: var(--primary-green);
            color: var(--text-primary);
        }
        
        .mode-button.active { 
            background: var(--primary-green); 
            color: #000;
            border-color: var(--primary-green);
        }
        
        .typing-indicator { 
            color: var(--text-secondary); 
            font-style: italic; 
            padding: 16px 20px;
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }
        
        .conversation-list {
            max-height: 200px;
            overflow-y: auto;
            margin-bottom: 20px;
        }
        
        .conversation-item {
            padding: 12px;
            background: var(--bg-tertiary);
            margin: 8px 0;
            border-radius: 8px;
            cursor: pointer;
            border: 1px solid var(--border-color);
            transition: all 0.3s ease;
        }
        
        .conversation-item:hover {
            border-color: var(--primary-green);
            background: rgba(0, 255, 136, 0.05);
        }
        
        .conversation-item.active {
            border-color: var(--primary-green);
            background: rgba(0, 255, 136, 0.1);
        }
        
        .conversation-preview {
            font-size: 12px;
            color: var(--text-secondary);
            margin-top: 4px;
            overflow: hidden;
            text-overflow: ellipsis;
            white-space: nowrap;
        }
        
        .stats-panel {
            background: var(--bg-tertiary);
            padding: 16px;
            border-radius: 8px;
            margin-top: 20px;
        }
        
        .stats-item {
            display: flex;
            justify-content: space-between;
            margin: 8px 0;
            font-size: 14px;
        }
        
        .connection-indicator {
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 14px;
        }
        
        .status-dot {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: var(--error-color);
            animation: pulse 2s infinite;
        }
        
        .status-dot.connected {
            background: var(--primary-green);
        }
        
        .insights-panel {
            background: rgba(0, 255, 136, 0.05);
            border: 1px solid rgba(0, 255, 136, 0.2);
            padding: 12px;
            border-radius: 8px;
            margin-top: 8px;
        }
        
        .insight-item {
            font-size: 12px;
            color: var(--text-secondary);
            margin: 4px 0;
        }
        
        .new-conversation-btn {
            width: 100%;
            padding: 12px;
            background: var(--primary-green);
            color: #000;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-weight: bold;
            font-size: 14px;
            margin-bottom: 20px;
            transition: all 0.3s ease;
        }
        
        .new-conversation-btn:hover {
            background: #00cc6a;
            transform: translateY(-1px);
        }
        
        @media (max-width: 768px) {
            .chat-container {
                grid-template-columns: 1fr;
            }
            
            .chat-sidebar {
                display: none;
            }
            
            .message {
                max-width: 95%;
            }
        }
    </style>
</head>
<body>
    <div class="chat-container">
        <div class="chat-sidebar">
            <div class="sidebar-header">
                <h3 style="margin: 0; color: var(--primary-green);">üí¨ ASIS Chat</h3>
                <p style="margin: 8px 0 0 0; font-size: 12px; color: var(--text-secondary);">Advanced Multi-Mode Interface</p>
            </div>
            
            <div class="sidebar-content">
                <button class="new-conversation-btn" onclick="startNewConversation()">
                    ‚ú® New Conversation
                </button>
                
                <div class="mode-selector" id="mode-selector">
                    <button class="mode-button active" data-mode="conversational">üí¨ Talk</button>
                    <button class="mode-button" data-mode="research">üî¨ Research</button>
                    <button class="mode-button" data-mode="creative">üé® Create</button>
                    <button class="mode-button" data-mode="learning">üìö Learn</button>
                    <button class="mode-button" data-mode="analysis">üîç Analyze</button>
                    <button class="mode-button" data-mode="monitoring">üìä Monitor</button>
                </div>
                
                <h4 style="color: var(--text-primary); margin-top: 20px;">Active Conversations</h4>
                <div class="conversation-list" id="conversation-list">
                    <!-- Conversations will be loaded here -->
                </div>
                
                <div class="stats-panel">
                    <h4 style="margin-top: 0; color: var(--text-primary);">Chat Statistics</h4>
                    <div class="stats-item">
                        <span>Messages:</span>
                        <span id="stats-messages">0</span>
                    </div>
                    <div class="stats-item">
                        <span>Avg Response:</span>
                        <span id="stats-response">0.0s</span>
                    </div>
                    <div class="stats-item">
                        <span>Confidence:</span>
                        <span id="stats-confidence">0%</span>
                    </div>
                </div>
            </div>
        </div>
        
        <div class="chat-main">
            <div class="chat-header">
                <div>
                    <h2 style="margin: 0; color: var(--text-primary);">ASIS Advanced Chat</h2>
                    <p style="margin: 4px 0 0 0; font-size: 14px; color: var(--text-secondary);">
                        Mode: <span id="current-mode-display">Conversational</span>
                    </p>
                </div>
                <div class="connection-indicator">
                    <div class="status-dot" id="connection-dot"></div>
                    <span id="connection-text">Connecting...</span>
                </div>
            </div>
            
            <div class="messages-container" id="messages-container">
                <div class="message asis-message">
                    <div class="message-header">
                        <span class="message-sender">üéØ ASIS</span>
                        <span class="message-time" id="welcome-time"></span>
                    </div>
                    <div class="message-content">
                        Welcome to the ASIS Advanced Chat Interface! I'm your AI assistant with multiple interaction modes. Choose a mode above and start chatting to experience context-aware, intelligent conversation.
                    </div>
                </div>
            </div>
            
            <div class="typing-indicator" id="typing-indicator" style="display: none;">
                üéØ ASIS is thinking...
            </div>
            
            <div class="input-area">
                <div class="input-container">
                    <textarea 
                        class="message-input" 
                        id="message-input" 
                        placeholder="Type your message here... (Shift+Enter for new line)"
                        rows="1"
                    ></textarea>
                    <button class="send-button" id="send-button" onclick="sendMessage()">Send</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        const socket = io();
        let currentConversationId = null;
        let currentMode = 'conversational';
        let isTyping = false;
        let conversationHistory = [];
        
        const modeDescriptions = {
            'conversational': 'Natural conversation and general assistance',
            'research': 'In-depth research and investigation',
            'creative': 'Creative thinking and ideation',
            'learning': 'Educational and learning support',
            'analysis': 'Detailed analysis and problem-solving',
            'monitoring': 'System monitoring and observation'
        };
        
        // Socket connection handlers
        socket.on('connect', function() {
            updateConnectionStatus(true);
            socket.emit('join_room', {room: 'chat'});
            startNewConversation();
        });
        
        socket.on('disconnect', function() {
            updateConnectionStatus(false);
        });
        
        socket.on('conversation_started', function(data) {
            currentConversationId = data.conversation_id;
            console.log('New conversation started:', currentConversationId);
            loadChatStatistics();
        });
        
        socket.on('chat_response', function(data) {
            displayMessage(data.response, 'asis', {
                confidence: data.confidence,
                processingTime: data.processing_time,
                insights: data.insights,
                mode: data.mode
            });
            hideTypingIndicator();
            updateChatStatistics(data);
        });
        
        socket.on('chat_typing', function(data) {
            if (data.conversation_id === currentConversationId) {
                showTypingIndicator();
            }
        });
        
        socket.on('mode_changed', function(data) {
            console.log('Mode changed to:', data.mode);
        });
        
        socket.on('error', function(data) {
            displayMessage('Error: ' + data.message, 'system');
            hideTypingIndicator();
        });
        
        // Initialize interface
        function init() {
            setupModeButtons();
            setupMessageInput();
            updateWelcomeTime();
            loadChatStatistics();
        }
        
        function setupModeButtons() {
            document.querySelectorAll('.mode-button').forEach(button => {
                button.addEventListener('click', function() {
                    const mode = this.dataset.mode;
                    switchMode(mode);
                });
            });
        }
        
        function setupMessageInput() {
            const input = document.getElementById('message-input');
            const sendButton = document.getElementById('send-button');
            
            input.addEventListener('keydown', function(e) {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    sendMessage();
                } else if (e.key === 'Enter' && e.shiftKey) {
                    // Allow new line
                    return;
                }
            });
            
            input.addEventListener('input', function() {
                this.style.height = 'auto';
                this.style.height = Math.min(this.scrollHeight, 120) + 'px';
                
                sendButton.disabled = !this.value.trim();
            });
            
            // Initial state
            sendButton.disabled = true;
        }
        
        function switchMode(mode) {
            currentMode = mode;
            
            // Update UI
            document.querySelectorAll('.mode-button').forEach(btn => {
                btn.classList.remove('active');
            });
            document.querySelector(`[data-mode="${mode}"]`).classList.add('active');
            
            // Update mode display
            const modeDisplay = document.getElementById('current-mode-display');
            modeDisplay.textContent = mode.charAt(0).toUpperCase() + mode.slice(1);
            
            // Notify server if in active conversation
            if (currentConversationId) {
                socket.emit('chat_change_mode', {
                    conversation_id: currentConversationId,
                    mode: mode
                });
            }
            
            // Add mode change message
            displayMessage(`Switched to ${mode} mode. ${modeDescriptions[mode]}`, 'system');
        }
        
        function startNewConversation() {
            socket.emit('chat_start_conversation', {
                user_id: 'demo_user_001',
                mode: currentMode
            });
            
            // Clear messages except welcome
            const messagesContainer = document.getElementById('messages-container');
            const messages = messagesContainer.querySelectorAll('.message:not(.asis-message:first-child)');
            messages.forEach(msg => msg.remove());
        }
        
        function sendMessage() {
            const input = document.getElementById('message-input');
            const message = input.value.trim();
            
            if (!message || !currentConversationId || isTyping) {
                return;
            }
            
            // Display user message
            displayMessage(message, 'user');
            
            // Clear input
            input.value = '';
            input.style.height = 'auto';
            document.getElementById('send-button').disabled = true;
            
            // Send to server
            socket.emit('chat_send_message', {
                conversation_id: currentConversationId,
                message: message,
                mode: currentMode,
                user_id: 'demo_user_001'
            });
        }
        
        function displayMessage(content, sender, metadata = {}) {
            const messagesContainer = document.getElementById('messages-container');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}-message`;
            
            const senderName = sender === 'user' ? 'You' : 
                              sender === 'system' ? 'üîß System' : 'üéØ ASIS';
            
            let messageHTML = `
                <div class="message-header">
                    <span class="message-sender">${senderName}</span>
                    <span class="message-time">${new Date().toLocaleTimeString()}</span>
                </div>
                <div class="message-content">${content}</div>
            `;
            
            // Add metadata for ASIS messages
            if (sender === 'asis' && metadata.confidence !== undefined) {
                const confidenceClass = metadata.confidence > 0.8 ? 'confidence-high' :
                                       metadata.confidence > 0.6 ? 'confidence-medium' : 'confidence-low';
                
                messageHTML += `
                    <div class="message-metadata">
                        <span class="confidence-indicator ${confidenceClass}">
                            Confidence: ${(metadata.confidence * 100).toFixed(0)}%
                        </span>
                        <span style="margin-left: 12px; color: var(--text-secondary);">
                            ${metadata.processingTime?.toFixed(2)}s
                        </span>
                        <span style="margin-left: 8px; color: var(--text-secondary);">
                            ${metadata.mode}
                        </span>
                    </div>
                `;
                
                // Add insights panel
                if (metadata.insights && metadata.insights.length > 0) {
                    messageHTML += `
                        <div class="insights-panel">
                            <div style="font-weight: bold; margin-bottom: 4px; color: var(--primary-green);">
                                üí° Autonomous Insights
                            </div>
                            ${metadata.insights.map(insight => 
                                `<div class="insight-item">‚Ä¢ ${insight}</div>`
                            ).join('')}
                        </div>
                    `;
                }
            }
            
            messageDiv.innerHTML = messageHTML;
            messagesContainer.appendChild(messageDiv);
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        }
        
        function showTypingIndicator() {
            const indicator = document.getElementById('typing-indicator');
            indicator.style.display = 'block';
            isTyping = true;
            
            const messagesContainer = document.getElementById('messages-container');
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        }
        
        function hideTypingIndicator() {
            document.getElementById('typing-indicator').style.display = 'none';
            isTyping = false;
        }
        
        function updateConnectionStatus(connected) {
            const dot = document.getElementById('connection-dot');
            const text = document.getElementById('connection-text');
            
            if (connected) {
                dot.classList.add('connected');
                text.textContent = 'Connected';
            } else {
                dot.classList.remove('connected');
                text.textContent = 'Disconnected';
            }
        }
        
        function updateWelcomeTime() {
            document.getElementById('welcome-time').textContent = new Date().toLocaleTimeString();
        }
        
        function updateChatStatistics(data) {
            // Update statistics in sidebar (simplified)
            if (data.confidence !== undefined) {
                document.getElementById('stats-confidence').textContent = 
                    (data.confidence * 100).toFixed(0) + '%';
            }
            
            if (data.processing_time !== undefined) {
                document.getElementById('stats-response').textContent = 
                    data.processing_time.toFixed(1) + 's';
            }
        }
        
        async function loadChatStatistics() {
            try {
                // This would typically fetch from an API endpoint
                // For now, using mock data
                document.getElementById('stats-messages').textContent = '0';
                document.getElementById('stats-response').textContent = '0.0s';
                document.getElementById('stats-confidence').textContent = '0%';
            } catch (error) {
                console.error('Failed to load chat statistics:', error);
            }
        }
        
        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', init);
    </script>
</body>
</html>
    '''

def main():
    """Main function to demonstrate advanced chat interface"""
    print("üí¨ ASIS Advanced Chat Interface System")
    print("=" * 50)
    
    # Update chat template
    with open('templates/chat.html', 'w', encoding='utf-8') as f:
        f.write(create_enhanced_chat_template())
    
    print("‚úÖ Enhanced chat interface template created")
    print("üéØ Multi-mode interaction system implemented")
    print("üîÑ Real-time WebSocket communication configured")
    print("üß† Context-aware message processing integrated")
    print("üìä Conversation analytics and insights added")
    print("üí° Autonomous insight generation included")

if __name__ == "__main__":
    main()
